{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRGydOoZWJpe"
      },
      "source": [
        "# Inisialisasi Kaggle API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLxdnOjDyNuw"
      },
      "outputs": [],
      "source": [
        "! chmod 600 /content/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaDcX-DNWovc",
        "outputId": "5757988e-c24c-4c38-badf-ffe43b290301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kaggle\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 2.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=743f7f9a81b949356afbcee357ea9db90fe15f82892ef907da2fabb4438a9030\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xxqv41ZaW-23",
        "outputId": "7f636985-3e40-4be3-9c2d-e61d8bcf1bc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading koi-dataset.zip to /content\n",
            " 66% 56.0M/84.3M [00:00<00:00, 76.3MB/s]\n",
            "100% 84.3M/84.3M [00:00<00:00, 105MB/s] \n"
          ]
        }
      ],
      "source": [
        "! KAGGLE_CONFIG_DIR=/content/ kaggle datasets download -d nafianmuh/koi-dataset #kaggle datasets download -d nafianmuh/koi-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "CYuEuZ5pH8qY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGIhxwQzNoWg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me-RmRnhXDiF"
      },
      "outputs": [],
      "source": [
        "zip_file = zipfile.ZipFile('koi-dataset.zip','r')\n",
        "zip_file.extractall('/tmp/dataset/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMe8JxRNDwtb",
        "outputId": "75c60389-08ab-4ae4-db50-e0f73a52197e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pyright-97-pZP8roHYAn17', 'pyright-97-GAa7UD06l7BB', 'dataset', 'initgoogle_syslog_dir.0', 'dap_multiplexer.INFO', 'debugger_2rh9lszbxk', 'dap_multiplexer.b393ba734790.root.log.INFO.20220611-060743.43', 'python-languageserver-cancellation']\n",
            "['Sanke', 'Goshiki', 'Bekko', 'Utsurimono', 'Shusui', 'Kohaku', 'Koromo', 'Showa', 'Asagi', 'Hikarimono']\n"
          ]
        }
      ],
      "source": [
        "print(os.listdir('/tmp/'))\n",
        "print(os.listdir('/tmp/dataset/Dataset'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHQ6OVqoYqXz"
      },
      "outputs": [],
      "source": [
        "#class_names = ['Utsurimono', 'Sanke', 'Showa','Chagoi', 'Shusui','Shiro', 'Asagi', 'Koromo', 'Tancho', 'Kohaku']\n",
        "class_names = ['Hikarimono', 'Koromo', 'Asagi', 'Utsurimono', 'Sanke', 'Shusui', 'Goshiki', 'Bekko', 'Showa', 'Kohaku']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcstuAG-LjXx",
        "outputId": "310d2cfa-7e5a-4100-83e4-ca95114752e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 56 images of Hikarimono koi.\n",
            "There are 39 images of Koromo koi.\n",
            "There are 33 images of Asagi koi.\n",
            "There are 24 images of Utsurimono koi.\n",
            "There are 65 images of Sanke koi.\n",
            "There are 44 images of Shusui koi.\n",
            "There are 85 images of Goshiki koi.\n",
            "There are 92 images of Bekko koi.\n",
            "There are 23 images of Showa koi.\n",
            "There are 35 images of Kohaku koi.\n"
          ]
        }
      ],
      "source": [
        "source_path = '/tmp/dataset/Dataset/'\n",
        "source_path_koi = []\n",
        "for names in class_names: \n",
        "  source_path_koi.append(os.path.join(source_path, names))\n",
        "\n",
        "for labels in source_path_koi:\n",
        "  print(f\"There are {len(os.listdir(labels))} images of {os.path.basename(labels)} koi.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGIIykS1XlUn",
        "outputId": "92f7606d-492f-4991-e876-0344bf588ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/dataset/Dataset/Hikarimono\n",
            "/tmp/dataset/Dataset/Koromo\n",
            "/tmp/dataset/Dataset/Asagi\n",
            "/tmp/dataset/Dataset/Utsurimono\n",
            "/tmp/dataset/Dataset/Sanke\n",
            "/tmp/dataset/Dataset/Shusui\n",
            "/tmp/dataset/Dataset/Goshiki\n",
            "/tmp/dataset/Dataset/Bekko\n",
            "/tmp/dataset/Dataset/Showa\n",
            "/tmp/dataset/Dataset/Kohaku\n"
          ]
        }
      ],
      "source": [
        "for labels in source_path_koi:\n",
        "  print(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create train and test directory"
      ],
      "metadata": {
        "id": "DzsfB4zmIB-V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Co-fgVPCMmlV"
      },
      "outputs": [],
      "source": [
        "# Define root directory\n",
        "root_dir = '/tmp/koi'\n",
        "\n",
        "# Empty directory to prevent FileExistsError is the function is run several times\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "\n",
        "# GRADED FUNCTION: create_train_test_dirs\n",
        "def create_train_test_dirs(root_path):\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # HINT:\n",
        "  # Use os.makedirs to create your directories with intermediate subdirectories\n",
        "  # Don't hardcode the paths. Use os.path.join to append the new directories to the root_path parameter\n",
        "  training_dir = 'training'\n",
        "  testing_dir = 'testing'\n",
        "  training_path = os.path.join(root_path,training_dir)\n",
        "  testing_path = os.path.join(root_path, testing_dir)\n",
        "\n",
        "  for path in source_path_koi:\n",
        "    os.makedirs(os.path.join(training_path, os.path.basename(path)))\n",
        "\n",
        "    os.makedirs(os.path.join(testing_path, os.path.basename(path)))\n",
        "\n",
        "  pass\n",
        "\n",
        "  ### END CODE HERE\n",
        "\n",
        "  \n",
        "try:\n",
        "  create_train_test_dirs(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQPmpsrtNhpQ"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: split_data\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "\n",
        "  ### START CODE HERE\n",
        "  content = random.sample(os.listdir(SOURCE),len(os.listdir(SOURCE)))\n",
        "\n",
        "  for index, name in enumerate(content):\n",
        "    if os.path.getsize(os.path.join(SOURCE, name)) == 0:\n",
        "      print('{} is zero length, so ignoring.'.format(name))\n",
        "      del content[index]\n",
        "      \n",
        "  \n",
        "  splitsize = int(len(content)) * SPLIT_SIZE\n",
        "  count = 0 \n",
        "  \n",
        "  for x in content:\n",
        "    if count != int(splitsize):\n",
        "      copyfile(os.path.join(SOURCE, x), os.path.join(TRAINING,x))\n",
        "      count += 1\n",
        "    else:\n",
        "      copyfile(os.path.join(SOURCE, x), os.path.join(TESTING,x))\n",
        "  \n",
        "  ### END CODE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt3dqakKPPto",
        "outputId": "8466dafe-b088-43ac-e958-a2cad5acd99d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/koi/training\n",
            "/tmp/koi/testing\n",
            "/tmp/koi/training/Sanke\n",
            "/tmp/koi/training/Goshiki\n",
            "/tmp/koi/training/Bekko\n",
            "/tmp/koi/training/Utsurimono\n",
            "/tmp/koi/training/Shusui\n",
            "/tmp/koi/training/Kohaku\n",
            "/tmp/koi/training/Koromo\n",
            "/tmp/koi/training/Showa\n",
            "/tmp/koi/training/Asagi\n",
            "/tmp/koi/training/Hikarimono\n",
            "/tmp/koi/testing/Sanke\n",
            "/tmp/koi/testing/Goshiki\n",
            "/tmp/koi/testing/Bekko\n",
            "/tmp/koi/testing/Utsurimono\n",
            "/tmp/koi/testing/Shusui\n",
            "/tmp/koi/testing/Kohaku\n",
            "/tmp/koi/testing/Koromo\n",
            "/tmp/koi/testing/Showa\n",
            "/tmp/koi/testing/Asagi\n",
            "/tmp/koi/testing/Hikarimono\n"
          ]
        }
      ],
      "source": [
        "for rootdir, dirs, files in os.walk(root_dir):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHzX-2npNsTA",
        "outputId": "a29cbba1-7340-4b6b-8c3a-003bda145e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are 44 images of Hikarimono for training\n",
            "\n",
            "There are 31 images of Koromo for training\n",
            "\n",
            "There are 26 images of Asagi for training\n",
            "\n",
            "There are 19 images of Utsurimono for training\n",
            "\n",
            "There are 52 images of Sanke for training\n",
            "\n",
            "There are 35 images of Shusui for training\n",
            "\n",
            "There are 68 images of Goshiki for training\n",
            "\n",
            "There are 73 images of Bekko for training\n",
            "\n",
            "There are 18 images of Showa for training\n",
            "\n",
            "There are 28 images of Kohaku for training\n",
            "\n",
            "There are 12 images of Hikarimono for testing\n",
            "\n",
            "There are 8 images of Koromo for testing\n",
            "\n",
            "There are 7 images of Asagi for testing\n",
            "\n",
            "There are 5 images of Utsurimono for testing\n",
            "\n",
            "There are 13 images of Sanke for testing\n",
            "\n",
            "There are 9 images of Shusui for testing\n",
            "\n",
            "There are 17 images of Goshiki for testing\n",
            "\n",
            "There are 19 images of Bekko for testing\n",
            "\n",
            "There are 5 images of Showa for testing\n",
            "\n",
            "There are 7 images of Kohaku for testing\n"
          ]
        }
      ],
      "source": [
        "# Test your split_data function\n",
        "\n",
        "# Define paths\n",
        "SOURCE_DIR_KOI = []\n",
        "for koi in class_names:\n",
        "  SOURCE_DIR_KOI.append('/tmp/dataset/Dataset/' + ''.join([koi, '/']))\n",
        "\n",
        "TRAINING_DIR = \"/tmp/koi/training/\"\n",
        "TESTING_DIR = \"/tmp/koi/testing/\"\n",
        "\n",
        "TRAINING_KOI_DIR = []\n",
        "TESTING_KOI_DIR = []\n",
        "\n",
        "for koi in class_names:\n",
        "  TRAINING_KOI_DIR.append(os.path.join(TRAINING_DIR, ''.join([koi, '/'])))\n",
        "  TESTING_KOI_DIR.append(os.path.join(TESTING_DIR, ''.join([koi, '/'])))\n",
        "\n",
        "\n",
        "# Empty directories in case you run this cell multiple times\n",
        "for koi in TRAINING_KOI_DIR:\n",
        "  if len(os.listdir(koi)) > 0:\n",
        "    for file in os.scandir(koi):\n",
        "      os.remove(file.path)\n",
        "\n",
        "for koi in TESTING_KOI_DIR:\n",
        "  if len(os.listdir(koi)) > 0:\n",
        "    for file in os.scandir(koi):\n",
        "      os.remove(file.path)\n",
        "\n",
        "# Define proportion of images used for training\n",
        "split_size = .8\n",
        "\n",
        "# Run the function\n",
        "# NOTE: Messages about zero length images should be printed out\n",
        "for index in range(len(SOURCE_DIR_KOI)):\n",
        "  split_data(SOURCE_DIR_KOI[index], TRAINING_KOI_DIR[index], TESTING_KOI_DIR[index],split_size)\n",
        "\n",
        "# Check that the number of images matches the expected output\n",
        "for training in TRAINING_KOI_DIR:\n",
        "  print(f\"\\nThere are {len(os.listdir(training))} images of {os.path.basename(os.path.dirname(training))} for training\")\n",
        "\n",
        "for testing in TESTING_KOI_DIR:\n",
        "  print(f\"\\nThere are {len(os.listdir(testing))} images of {os.path.basename(os.path.dirname(testing))} for testing\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPzi9u-LYK_d"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: train_val_generators\n",
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the arguments to augment the images)\n",
        "  train_datagen = ImageDataGenerator(rescale= 1/255.,\n",
        "                                     rotation_range= 40,\n",
        "                                     width_shift_range= 0.2,\n",
        "                                     height_shift_range= 0.2,\n",
        "                                     shear_range= 0.2,\n",
        "                                     zoom_range= 0.2,\n",
        "                                     horizontal_flip= True,\n",
        "                                     fill_mode= 'nearest')\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(directory= TRAINING_DIR,\n",
        "                                                      batch_size= 16,\n",
        "                                                      class_mode= 'categorical',\n",
        "                                                      target_size=(150, 150))\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  validation_datagen = ImageDataGenerator(rescale= 1/255.)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory= VALIDATION_DIR,\n",
        "                                                                batch_size= 16,\n",
        "                                                                class_mode= 'categorical',\n",
        "                                                                target_size=(150, 150))\n",
        "  ### END CODE HERE\n",
        "  return train_generator, validation_generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXozTi8DYZWl",
        "outputId": "d50fee9f-45a5-4923-97e7-50e584ba7548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 394 images belonging to 10 classes.\n",
            "Found 102 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "# Test your generators\n",
        "train_generator, validation_generator = train_val_generators(TRAINING_DIR, TESTING_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training with Transfer Learning of Mobilenet_V2 --> Used Model for Deploy in Android\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "iLvJ3HVVq0lM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "ZGk4tHlvrICS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module_selection = (\"mobilenet_v2\", 224, 1280) #@param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n",
        "handle_base, pixels, FV_SIZE = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK8Lj8W_rCip",
        "outputId": "f988b143-dd8d-4179-c972-182fefa8b659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 with input size (224, 224) and output dimension 1280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "do_fine_tuning = False #@param {type:\"boolean\"}"
      ],
      "metadata": {
        "id": "SmI9dCelqz5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                   input_shape=(224,224) + (3,), \n",
        "                                   output_shape=[FV_SIZE],\n",
        "                                   trainable=do_fine_tuning)"
      ],
      "metadata": {
        "id": "DLbATFM0q4Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        feature_extractor,\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzs7Zt-CrVqj",
        "outputId": "70c9b7e6-0644-4e35-92a6-452c91991771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model with https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_1 (KerasLayer)  (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,270,794\n",
            "Trainable params: 12,810\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: train_val_generators\n",
        "def train_val_generator(TRAINING_DIR, VALIDATION_DIR):\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the arguments to augment the images)\n",
        "  train_datagen = ImageDataGenerator(rescale= 1/255.,\n",
        "                                     rotation_range= 40,\n",
        "                                     width_shift_range= 0.2,\n",
        "                                     height_shift_range= 0.2,\n",
        "                                     shear_range= 0.2,\n",
        "                                     zoom_range= 0.2,\n",
        "                                     horizontal_flip= True,\n",
        "                                     fill_mode= 'nearest')\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(directory= TRAINING_DIR,\n",
        "                                                      batch_size= 16,\n",
        "                                                      class_mode= 'categorical',\n",
        "                                                      target_size=(224, 224))\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  validation_datagen = ImageDataGenerator(rescale= 1/255.)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory= VALIDATION_DIR,\n",
        "                                                                batch_size= 16,\n",
        "                                                                class_mode= 'categorical',\n",
        "                                                                target_size=(224, 224))\n",
        "  ### END CODE HERE\n",
        "  return train_generator, validation_generator\n"
      ],
      "metadata": {
        "id": "KynOz5DmiJVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your generators\n",
        "train_generator, validation_generator = train_val_generator(TRAINING_DIR, TESTING_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYzrNsGUiXoW",
        "outputId": "7f7ff9c9-532e-4440-bcc8-295ac823e123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 394 images belonging to 10 classes.\n",
            "Found 102 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unfreeze some layers\n",
        "NUM_LAYERS = 10 \n",
        "      \n",
        "if do_fine_tuning:\n",
        "    feature_extractor.trainable = True\n",
        "    \n",
        "    for layer in model.layers[-NUM_LAYERS:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "else:\n",
        "    feature_extractor.trainable = False"
      ],
      "metadata": {
        "id": "TFWpIKD3wmqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if do_fine_tuning:\n",
        "    model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.002, momentum=0.9),\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "else:\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GVB8e67-wocM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "hist = model.fit(train_generator,\n",
        "                 epochs=EPOCHS,\n",
        "                 validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT3zhS_dwq4X",
        "outputId": "e00b9d38-ed6c-4956-af43-b294873f13e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "25/25 [==============================] - 24s 919ms/step - loss: 0.3138 - accuracy: 0.9264 - val_loss: 0.4844 - val_accuracy: 0.8725\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - 20s 803ms/step - loss: 0.2722 - accuracy: 0.9365 - val_loss: 0.4789 - val_accuracy: 0.8431\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - 20s 803ms/step - loss: 0.2293 - accuracy: 0.9619 - val_loss: 0.4228 - val_accuracy: 0.8922\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - 20s 795ms/step - loss: 0.1943 - accuracy: 0.9645 - val_loss: 0.4191 - val_accuracy: 0.8725\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - 20s 796ms/step - loss: 0.2014 - accuracy: 0.9594 - val_loss: 0.3771 - val_accuracy: 0.9020\n",
            "Epoch 6/20\n",
            "25/25 [==============================] - 20s 792ms/step - loss: 0.1817 - accuracy: 0.9594 - val_loss: 0.3809 - val_accuracy: 0.8922\n",
            "Epoch 7/20\n",
            "25/25 [==============================] - 20s 799ms/step - loss: 0.1763 - accuracy: 0.9670 - val_loss: 0.3646 - val_accuracy: 0.9118\n",
            "Epoch 8/20\n",
            "25/25 [==============================] - 20s 782ms/step - loss: 0.1731 - accuracy: 0.9746 - val_loss: 0.3877 - val_accuracy: 0.9020\n",
            "Epoch 9/20\n",
            "25/25 [==============================] - 20s 788ms/step - loss: 0.1396 - accuracy: 0.9746 - val_loss: 0.3603 - val_accuracy: 0.9216\n",
            "Epoch 10/20\n",
            "25/25 [==============================] - 21s 843ms/step - loss: 0.1519 - accuracy: 0.9543 - val_loss: 0.3601 - val_accuracy: 0.9020\n",
            "Epoch 11/20\n",
            "25/25 [==============================] - 20s 786ms/step - loss: 0.1192 - accuracy: 0.9772 - val_loss: 0.3665 - val_accuracy: 0.8922\n",
            "Epoch 12/20\n",
            "25/25 [==============================] - 20s 785ms/step - loss: 0.1058 - accuracy: 0.9848 - val_loss: 0.3669 - val_accuracy: 0.9216\n",
            "Epoch 13/20\n",
            "25/25 [==============================] - 20s 784ms/step - loss: 0.1165 - accuracy: 0.9746 - val_loss: 0.3461 - val_accuracy: 0.9216\n",
            "Epoch 14/20\n",
            "25/25 [==============================] - 20s 785ms/step - loss: 0.0955 - accuracy: 0.9873 - val_loss: 0.3896 - val_accuracy: 0.8824\n",
            "Epoch 15/20\n",
            "25/25 [==============================] - 20s 786ms/step - loss: 0.1065 - accuracy: 0.9822 - val_loss: 0.3504 - val_accuracy: 0.9118\n",
            "Epoch 16/20\n",
            "25/25 [==============================] - 20s 786ms/step - loss: 0.0967 - accuracy: 0.9822 - val_loss: 0.3475 - val_accuracy: 0.9118\n",
            "Epoch 17/20\n",
            "25/25 [==============================] - 20s 796ms/step - loss: 0.1141 - accuracy: 0.9721 - val_loss: 0.3457 - val_accuracy: 0.9118\n",
            "Epoch 18/20\n",
            "25/25 [==============================] - 20s 791ms/step - loss: 0.1161 - accuracy: 0.9772 - val_loss: 0.3471 - val_accuracy: 0.9216\n",
            "Epoch 19/20\n",
            "25/25 [==============================] - 20s 786ms/step - loss: 0.0916 - accuracy: 0.9797 - val_loss: 0.4096 - val_accuracy: 0.9020\n",
            "Epoch 20/20\n",
            "25/25 [==============================] - 20s 785ms/step - loss: 0.1083 - accuracy: 0.9746 - val_loss: 0.3394 - val_accuracy: 0.9314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=hist.history['accuracy']\n",
        "val_acc=hist.history['val_accuracy']\n",
        "loss=hist.history['loss']\n",
        "val_loss=hist.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "gkhIjCYpk1rF",
        "outputId": "8ef3990b-d791-4d0d-830c-9bcbe96a123b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Test Used Model --> Transfer Learning of Mobilenet_V2"
      ],
      "metadata": {
        "id": "qC2gUnAutNZ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "BQCg0Ts9uMMr",
        "outputId": "9340ba08-7e55-48ad-fd91-e33684d02216"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8bfe2f8e-5331-4127-8b71-08014c632d07\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8bfe2f8e-5331-4127-8b71-08014c632d07\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving a_000001.png to a_000001 (1).png\n",
            "[1.12115595e-04 1.75541019e-04 2.59921048e-03 2.58488534e-03\n",
            " 9.89714026e-01 2.70426361e-04 3.52120353e-03 4.87913319e-04\n",
            " 3.92793532e-04 1.42082892e-04]\n",
            "Kohaku\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path='/content/' + fn\n",
        "  img=image.load_img(path, target_size=(224, 224))\n",
        "  \n",
        "  x=image.img_to_array(img)\n",
        "  x /= 255.\n",
        "  x=np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  \n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  print(classes[0])\n",
        "\n",
        "  class_names = ['Asagi', 'Bekko', 'Goshiki', 'Hikarimono', 'Kohaku', 'Koromo', 'Sanke', 'Showa', 'Shusui', 'Utsurimono']\n",
        "  \n",
        "  max = 0\n",
        "  index = 0\n",
        "  num = 0\n",
        "  loop = 0\n",
        "\n",
        "  for num in classes[0]:\n",
        "    loop += 1\n",
        "    if num >= max:\n",
        "      max = num\n",
        "      index = loop\n",
        "    \n",
        "  print(class_names[index-1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKaXuvJnEcVJ"
      },
      "source": [
        "# Export Model to TFLite and Optimizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ErEHyzzBGCm"
      },
      "outputs": [],
      "source": [
        "KOI_SAVED_MODEL = \"exp_saved_model_2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xypbt7t2Hm8g",
        "outputId": "3f17d526-0a56-4e6c-88ad-73570337ec7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: exp_saved_model_2/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: exp_saved_model_2/assets\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(model, KOI_SAVED_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ox0ZyTiHr3k",
        "outputId": "d49d15ed-3a02-4d7a-e4e9-2d326525248c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['keras_layer_1_input'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 224, 224, 3)\n",
            "      name: serving_default_keras_layer_1_input:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['dense_5'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 10)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ],
      "source": [
        "%%bash -s $KOI_SAVED_MODEL\n",
        "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEj8dorCH0NV"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load(KOI_SAVED_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03n7kO-LH80C",
        "outputId": "ac864bbf-cdac-42f2-8f8d-a4ea400a6dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['serving_default']\n",
            "((), {'keras_layer_1_input': TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_layer_1_input')})\n",
            "{'dense_5': TensorSpec(shape=(None, 10), dtype=tf.float32, name='dense_5')}\n"
          ]
        }
      ],
      "source": [
        "print(list(loaded.signatures.keys()))\n",
        "infer = loaded.signatures[\"serving_default\"]\n",
        "print(infer.structured_input_signature)\n",
        "print(infer.structured_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(KOI_SAVED_MODEL)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "                                       tf.lite.OpsSet.SELECT_TF_OPS]"
      ],
      "metadata": {
        "id": "XAAS8M1vIFjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkipIp91YSxh"
      },
      "outputs": [],
      "source": [
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlnXyi9JYXLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3baf7dae-fe6d-42f9-b54e-51d891e4bf50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "tflite_model = converter.convert()\n",
        "tflite_model_file = 'model_small.tflite'\n",
        "\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the TFLite Model Using the Python Interpreter"
      ],
      "metadata": {
        "id": "SK4UwMX-ZHHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "EghIXaxKZYzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "  \n",
        "interpreter = tf.lite.Interpreter(model_path=\"/content/model_small.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]"
      ],
      "metadata": {
        "id": "c62Mq0O6G1rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gather results for the randomly sampled test images\n",
        "predictions = []\n",
        "\n",
        "test_labels, test_imgs = [], []\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path='/content/' + fn\n",
        "  img=image.load_img(path, target_size=(224, 224))\n",
        "  \n",
        "  x=image.img_to_array(img)\n",
        "  x /= 255.\n",
        "  x=np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])    \n",
        "  interpreter.set_tensor(input_index, images)\n",
        "  interpreter.invoke()\n",
        "  arrayofpredict = interpreter.get_tensor(output_index)\n",
        "  class_names = ['Asagi', 'Bekko', 'Goshiki', 'Hikarimono', 'Kohaku', 'Koromo', 'Sanke', 'Showa', 'Shusui', 'Utsurimono']\n",
        "  \n",
        "  #print(type())\n",
        "  max = 0\n",
        "  index = 0\n",
        "  num = 0\n",
        "  loop = 0\n",
        "\n",
        "  for num in arrayofpredict[0]:\n",
        "    loop += 1\n",
        "    if num >= max:\n",
        "      max = num\n",
        "      index = loop\n",
        "    \n",
        "  print(arrayofpredict[0])\n",
        "  print(f\"Ini adalah ikan koi {class_names[index-1]} --> akurasi {max}\")\n",
        "  #print(label.numpy()[0])\n",
        "  #print(images)"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "e2HMMUliZXNM",
        "outputId": "1e34157b-02eb-46b2-8bb4-f25a00ec635e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d09b06bf-d3f5-4ed5-9e71-eb0f93d7f323\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d09b06bf-d3f5-4ed5-9e71-eb0f93d7f323\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving t0806t014.jpg to t0806t014.jpg\n",
            "[6.7304100e-06 3.3424437e-04 2.7955605e-03 4.8233673e-05 2.5747868e-05\n",
            " 7.5501192e-04 4.5772811e-04 7.8035243e-02 7.9879450e-05 9.1746169e-01]\n",
            "Ini adalah ikan koi Utsurimono --> akurasi 0.9174616932868958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add Metadata to Model "
      ],
      "metadata": {
        "id": "S8wlOsCNqZid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade flatbuffers==1.12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOdFDVDpqb1c",
        "outputId": "8b235fa1-f6c8-42dc-8091-c1d1c20a907a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flatbuffers==1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: flatbuffers\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "Successfully installed flatbuffers-1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflite_support"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "J7wmevLPqfR8",
        "outputId": "94472f98-14d7-471e-9ac2-20970678f238"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflite_support\n",
            "  Downloading tflite_support-0.4.1-cp37-cp37m-manylinux2014_x86_64.whl (42.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.5 MB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from tflite_support) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tflite_support) (1.0.0)\n",
            "Collecting protobuf<4,>=3.18.0\n",
            "  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 41.5 MB/s \n",
            "\u001b[?25hCollecting sounddevice>=0.4.4\n",
            "  Downloading sounddevice-0.4.4-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tflite_support) (1.12)\n",
            "Collecting pybind11>=2.6.0\n",
            "  Downloading pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 41.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.0->tflite_support) (1.15.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.7/dist-packages (from sounddevice>=0.4.4->tflite_support) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite_support) (2.21)\n",
            "Installing collected packages: sounddevice, pybind11, protobuf, tflite-support\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\n",
            "Successfully installed protobuf-3.20.1 pybind11-2.9.2 sounddevice-0.4.4 tflite-support-0.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tflite_support.metadata_writers import image_classifier\n",
        "from tflite_support.metadata_writers import writer_utils"
      ],
      "metadata": {
        "id": "ZMgYjCVsqhZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ImageClassifierWriter = image_classifier.MetadataWriter\n",
        "_MODEL_PATH = \"/content/model_small.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"/content/label.txt\"\n",
        "_SAVE_TO_PATH = \"/content/model_small_with_metadata.tflite\"\n",
        "# Normalization parameters is required when reprocessing the image. It is\n",
        "# optional if the image pixel values are in range of [0, 255] and the input\n",
        "# tensor is quantized to uint8. See the introduction for normalization and\n",
        "# quantization parameters below for more details.\n",
        "# https://www.tensorflow.org/lite/models/convert/metadata#normalization_and_quantization_parameters)\n",
        "_INPUT_NORM_MEAN = 127.5\n",
        "_INPUT_NORM_STD = 127.5\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = ImageClassifierWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ],
      "metadata": {
        "id": "M7T3oUOQqnRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Metadata into Json File"
      ],
      "metadata": {
        "id": "ZP0K3s5xq2t7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import tflite_runtime.interpreter as tflite\n",
        "import tensorflow as tf\n",
        "model_path=\"/content/model_small_with_metadata.tflite\"\n",
        "interpreter = tf.lite.Interpreter(model_path)"
      ],
      "metadata": {
        "id": "ucec24_nqz1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "displayer = _metadata.MetadataDisplayer.with_model_file(model_path)\n",
        "export_json_file = \"/content/extracted_metadata.json\"\n",
        "json_file = displayer.get_metadata_json()\n",
        "\n",
        "# Optional: write out the metadata as a json file\n",
        "with open(export_json_file, \"w\") as f:\n",
        "  f.write(json_file)"
      ],
      "metadata": {
        "id": "99bJXjaLq5vK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Koi Tensorflow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}